{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZiSewEzcvNt0"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages and setup display\n",
        "!pip install ultralytics\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.figsize'] = [20, 10]\n",
        "%config InlineBackend.figure_format = 'retina'"
      ],
      "metadata": {
        "id": "MhB8cbfSvQv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Object detection using Semantic Segmentation\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import os\n",
        "from pathlib import Path\n",
        "import logging\n",
        "from datetime import datetime\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO,\n",
        "                   format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Print current directory contents to verify images\n",
        "print(\"Current directory contents:\")\n",
        "print(os.listdir())\n",
        "\n",
        "class NightVisionSystem:\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the night vision system\"\"\"\n",
        "        logger.info(\"Loading YOLOv5 model...\")\n",
        "        try:\n",
        "            self.model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
        "            self.model.conf = 0.5\n",
        "            self.model.iou = 0.45\n",
        "            self.model.classes = None\n",
        "            self.model.max_det = 1000\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error loading YOLOv5 model: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "        self.target_classes = {\n",
        "            'person': 'person',\n",
        "            'car': 'vehicle',\n",
        "            'truck': 'vehicle',\n",
        "            'motorcycle': 'vehicle',\n",
        "            'bus': 'vehicle',\n",
        "            'bicycle': 'vehicle',\n",
        "            'dog': 'animal',\n",
        "            'cat': 'animal',\n",
        "            'horse': 'animal',\n",
        "            'cow': 'animal',\n",
        "            'sheep': 'animal'\n",
        "        }\n",
        "\n",
        "        self.object_colors = {\n",
        "            'person': (0, 255, 0),\n",
        "            'car': (255, 0, 0),\n",
        "            'truck': (255, 127, 0),\n",
        "            'motorcycle': (255, 0, 127),\n",
        "            'bus': (255, 127, 127),\n",
        "            'bicycle': (200, 200, 0),\n",
        "            'dog': (0, 0, 255),\n",
        "            'cat': (0, 127, 255),\n",
        "            'horse': (0, 255, 255),\n",
        "            'cow': (127, 0, 255),\n",
        "            'sheep': (127, 127, 255)\n",
        "        }\n",
        "\n",
        "        self.legend_start_x = 10\n",
        "        self.legend_start_y = 30\n",
        "        self.legend_entry_height = 25\n",
        "        self.legend_text_offset = 30\n",
        "\n",
        "    def enhance_image(self, image):\n",
        "        r_channel, g_channel, b_channel = cv2.split(image)\n",
        "        r_eq = cv2.equalizeHist(r_channel)\n",
        "        g_eq = cv2.equalizeHist(g_channel)\n",
        "        b_eq = cv2.equalizeHist(b_channel)\n",
        "        hist_eq_image = cv2.merge((r_eq, g_eq, b_eq))\n",
        "\n",
        "        lab = cv2.cvtColor(hist_eq_image, cv2.COLOR_BGR2LAB)\n",
        "        l_channel, a_channel, b_channel = cv2.split(lab)\n",
        "        clahe = cv2.createCLAHE(clipLimit=10.0, tileGridSize=(10, 10))\n",
        "        l_channel_eq = clahe.apply(l_channel)\n",
        "        lab_eq = cv2.merge((l_channel_eq, a_channel, b_channel))\n",
        "        clahe_image = cv2.cvtColor(lab_eq, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "        bilateral_filtered = cv2.bilateralFilter(clahe_image, d=2, sigmaColor=50, sigmaSpace=50)\n",
        "\n",
        "        gamma = 1.2\n",
        "        gamma_corrected = np.array(255 * (bilateral_filtered / 255) ** gamma, dtype='uint8')\n",
        "\n",
        "        gaussian_blur = cv2.GaussianBlur(gamma_corrected, (0, 0), 2.0)\n",
        "        enhanced_image = cv2.addWeighted(gamma_corrected, 2, gaussian_blur, -1, 0)\n",
        "\n",
        "        return enhanced_image\n",
        "\n",
        "    def detect_objects(self, image):\n",
        "        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        results = self.model(rgb_image)\n",
        "        detections = []\n",
        "\n",
        "        for pred in results.xyxy[0]:\n",
        "            x1, y1, x2, y2, conf, cls = pred.cpu().numpy()\n",
        "            class_name = self.model.names[int(cls)]\n",
        "\n",
        "            if class_name in self.target_classes:\n",
        "                category = self.target_classes[class_name]\n",
        "                detections.append({\n",
        "                    'category': category,\n",
        "                    'class': class_name,\n",
        "                    'confidence': float(conf),\n",
        "                    'bbox': (int(x1), int(y1), int(x2), int(y2))\n",
        "                })\n",
        "\n",
        "        return detections\n",
        "\n",
        "    def add_color_legend(self, image, used_classes):\n",
        "        legend_width = 180\n",
        "        legend_height = len(used_classes) * self.legend_entry_height + 10\n",
        "\n",
        "        overlay = image.copy()\n",
        "        cv2.rectangle(overlay, (5, 5),\n",
        "                     (5 + legend_width, 5 + legend_height),\n",
        "                     (0, 0, 0), -1)\n",
        "        cv2.addWeighted(overlay, 0.7, image, 0.3, 0, image)\n",
        "\n",
        "        cv2.putText(image, \"Detected Objects:\",\n",
        "                   (self.legend_start_x, 20),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
        "\n",
        "        y_position = self.legend_start_y\n",
        "        for class_name in sorted(used_classes):\n",
        "            color = self.object_colors[class_name]\n",
        "\n",
        "            cv2.rectangle(image,\n",
        "                         (self.legend_start_x, y_position - 10),\n",
        "                         (self.legend_start_x + 20, y_position + 10),\n",
        "                         color, -1)\n",
        "\n",
        "            cv2.putText(image, class_name,\n",
        "                       (self.legend_start_x + self.legend_text_offset, y_position + 5),\n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
        "\n",
        "            y_position += self.legend_entry_height\n",
        "\n",
        "    def visualize_detections(self, image, detections):\n",
        "        result_image = image.copy()\n",
        "        used_classes = set()\n",
        "\n",
        "        for det in detections:\n",
        "            x1, y1, x2, y2 = det['bbox']\n",
        "            class_name = det['class']\n",
        "            color = self.object_colors[class_name]\n",
        "            used_classes.add(class_name)\n",
        "\n",
        "            cv2.rectangle(result_image, (x1, y1), (x2, y2), color, 2)\n",
        "\n",
        "            label = f\"{class_name} ({det['confidence']:.2f})\"\n",
        "            label_size, _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)\n",
        "\n",
        "            cv2.rectangle(result_image,\n",
        "                        (x1, y1 - label_size[1] - 10),\n",
        "                        (x1 + label_size[0], y1),\n",
        "                        color, -1)\n",
        "\n",
        "            cv2.putText(result_image, label, (x1, y1-5),\n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
        "\n",
        "        self.add_color_legend(result_image, used_classes)\n",
        "        return result_image\n",
        "\n",
        "    def process_image(self, image_path):\n",
        "        try:\n",
        "            image = cv2.imread(str(image_path))\n",
        "            if image is None:\n",
        "                raise ValueError(f\"Could not read image: {image_path}\")\n",
        "\n",
        "            enhanced_image = self.enhance_image(image)\n",
        "            detections = self.detect_objects(enhanced_image)\n",
        "            result_image = self.visualize_detections(enhanced_image, detections)\n",
        "\n",
        "            return {\n",
        "                'original': image,\n",
        "                'enhanced': enhanced_image,\n",
        "                'result': result_image,\n",
        "                'detections': detections\n",
        "            }\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error processing image {image_path}: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "# Initialize system and process images\n",
        "system = NightVisionSystem()\n",
        "image_paths = ['0.png', '1.png', '2.png', '3.png', '4.png']\n",
        "\n",
        "# Create a single figure for all images\n",
        "plt.figure(figsize=(20, 5 * len(image_paths)))\n",
        "\n",
        "for idx, image_path in enumerate(image_paths, 1):\n",
        "    try:\n",
        "        print(f\"\\nProcessing Image {idx}:\")\n",
        "        results = system.process_image(image_path)\n",
        "\n",
        "        # Plot in a single row\n",
        "        base_idx = (idx - 1) * 3 + 1\n",
        "\n",
        "        # Original image\n",
        "        plt.subplot(len(image_paths), 3, base_idx)\n",
        "        plt.imshow(cv2.cvtColor(results['original'], cv2.COLOR_BGR2RGB))\n",
        "        plt.title(f'Original Image {idx}')\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Enhanced image\n",
        "        plt.subplot(len(image_paths), 3, base_idx + 1)\n",
        "        plt.imshow(cv2.cvtColor(results['enhanced'], cv2.COLOR_BGR2RGB))\n",
        "        plt.title(f'Enhanced Image {idx}')\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Detection results\n",
        "        plt.subplot(len(image_paths), 3, base_idx + 2)\n",
        "        plt.imshow(cv2.cvtColor(results['result'], cv2.COLOR_BGR2RGB))\n",
        "        plt.title(f'Detected Objects {idx} ({len(results[\"detections\"])} objects)')\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Print detection summary\n",
        "        print(f\"Detections in Image {idx}:\")\n",
        "        categories = {}\n",
        "        for det in results['detections']:\n",
        "            cat = det['category']\n",
        "            categories[cat] = categories.get(cat, 0) + 1\n",
        "        for cat, count in categories.items():\n",
        "            print(f\"- {cat}: {count}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to process {image_path}: {str(e)}\")\n",
        "        print(f\"Error processing Image {idx}: {str(e)}\")\n",
        "        continue\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wM_8LiJvvTHo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}